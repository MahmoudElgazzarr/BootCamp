
Project_final.elf:     file format elf32-avr

Sections:
Idx Name          Size      VMA       LMA       File off  Algn
  0 .data         00000238  00800100  0000076e  000007e2  2**0
                  CONTENTS, ALLOC, LOAD, DATA
  1 .text         0000076e  00000000  00000000  00000074  2**1
                  CONTENTS, ALLOC, LOAD, READONLY, CODE
  2 .comment      00000030  00000000  00000000  00000a1a  2**0
                  CONTENTS, READONLY
  3 .note.gnu.avr.deviceinfo 00000040  00000000  00000000  00000a4c  2**2
                  CONTENTS, READONLY
  4 .debug_aranges 00000080  00000000  00000000  00000a8c  2**0
                  CONTENTS, READONLY, DEBUGGING
  5 .debug_info   00000e2f  00000000  00000000  00000b0c  2**0
                  CONTENTS, READONLY, DEBUGGING
  6 .debug_abbrev 00000a18  00000000  00000000  0000193b  2**0
                  CONTENTS, READONLY, DEBUGGING
  7 .debug_line   0000090b  00000000  00000000  00002353  2**0
                  CONTENTS, READONLY, DEBUGGING
  8 .debug_frame  00000190  00000000  00000000  00002c60  2**2
                  CONTENTS, READONLY, DEBUGGING
  9 .debug_str    00000425  00000000  00000000  00002df0  2**0
                  CONTENTS, READONLY, DEBUGGING
 10 .debug_loc    00001050  00000000  00000000  00003215  2**0
                  CONTENTS, READONLY, DEBUGGING
 11 .debug_ranges 00000088  00000000  00000000  00004265  2**0
                  CONTENTS, READONLY, DEBUGGING

Disassembly of section .text:

00000000 <__vectors>:
   0:	0c 94 34 00 	jmp	0x68	; 0x68 <__ctors_end>
   4:	0c 94 49 00 	jmp	0x92	; 0x92 <__bad_interrupt>
   8:	0c 94 49 00 	jmp	0x92	; 0x92 <__bad_interrupt>
   c:	0c 94 49 00 	jmp	0x92	; 0x92 <__bad_interrupt>
  10:	0c 94 49 00 	jmp	0x92	; 0x92 <__bad_interrupt>
  14:	0c 94 49 00 	jmp	0x92	; 0x92 <__bad_interrupt>
  18:	0c 94 49 00 	jmp	0x92	; 0x92 <__bad_interrupt>
  1c:	0c 94 49 00 	jmp	0x92	; 0x92 <__bad_interrupt>
  20:	0c 94 49 00 	jmp	0x92	; 0x92 <__bad_interrupt>
  24:	0c 94 49 00 	jmp	0x92	; 0x92 <__bad_interrupt>
  28:	0c 94 49 00 	jmp	0x92	; 0x92 <__bad_interrupt>
  2c:	0c 94 49 00 	jmp	0x92	; 0x92 <__bad_interrupt>
  30:	0c 94 49 00 	jmp	0x92	; 0x92 <__bad_interrupt>
  34:	0c 94 49 00 	jmp	0x92	; 0x92 <__bad_interrupt>
  38:	0c 94 49 00 	jmp	0x92	; 0x92 <__bad_interrupt>
  3c:	0c 94 49 00 	jmp	0x92	; 0x92 <__bad_interrupt>
  40:	0c 94 49 00 	jmp	0x92	; 0x92 <__bad_interrupt>
  44:	0c 94 49 00 	jmp	0x92	; 0x92 <__bad_interrupt>
  48:	0c 94 49 00 	jmp	0x92	; 0x92 <__bad_interrupt>
  4c:	0c 94 49 00 	jmp	0x92	; 0x92 <__bad_interrupt>
  50:	0c 94 49 00 	jmp	0x92	; 0x92 <__bad_interrupt>
  54:	0c 94 49 00 	jmp	0x92	; 0x92 <__bad_interrupt>
  58:	0c 94 49 00 	jmp	0x92	; 0x92 <__bad_interrupt>
  5c:	0c 94 49 00 	jmp	0x92	; 0x92 <__bad_interrupt>
  60:	0c 94 49 00 	jmp	0x92	; 0x92 <__bad_interrupt>
  64:	0c 94 49 00 	jmp	0x92	; 0x92 <__bad_interrupt>

00000068 <__ctors_end>:
  68:	11 24       	eor	r1, r1
  6a:	1f be       	out	0x3f, r1	; 63
  6c:	cf ef       	ldi	r28, 0xFF	; 255
  6e:	d8 e0       	ldi	r29, 0x08	; 8
  70:	de bf       	out	0x3e, r29	; 62
  72:	cd bf       	out	0x3d, r28	; 61

00000074 <__do_copy_data>:
  74:	13 e0       	ldi	r17, 0x03	; 3
  76:	a0 e0       	ldi	r26, 0x00	; 0
  78:	b1 e0       	ldi	r27, 0x01	; 1
  7a:	ee e6       	ldi	r30, 0x6E	; 110
  7c:	f7 e0       	ldi	r31, 0x07	; 7
  7e:	02 c0       	rjmp	.+4      	; 0x84 <__do_copy_data+0x10>
  80:	05 90       	lpm	r0, Z+
  82:	0d 92       	st	X+, r0
  84:	a8 33       	cpi	r26, 0x38	; 56
  86:	b1 07       	cpc	r27, r17
  88:	d9 f7       	brne	.-10     	; 0x80 <__do_copy_data+0xc>
  8a:	0e 94 42 03 	call	0x684	; 0x684 <main>
  8e:	0c 94 b5 03 	jmp	0x76a	; 0x76a <_exit>

00000092 <__bad_interrupt>:
  92:	0c 94 00 00 	jmp	0	; 0x0 <__vectors>

00000096 <aes_decrypt_128>:
    *(state+7)  = *(state+11);
    *(state+11) = *(state+15);
    *(state+15) = temp;
	return temp;
}
void aes_decrypt_128(const uint8_t *roundkeys, const uint8_t *ciphertext, uint8_t *plaintext) {
  96:	2f 92       	push	r2
  98:	3f 92       	push	r3
  9a:	4f 92       	push	r4
  9c:	5f 92       	push	r5
  9e:	6f 92       	push	r6
  a0:	7f 92       	push	r7
  a2:	8f 92       	push	r8
  a4:	9f 92       	push	r9
  a6:	af 92       	push	r10
  a8:	bf 92       	push	r11
  aa:	cf 92       	push	r12
  ac:	df 92       	push	r13
  ae:	ef 92       	push	r14
  b0:	ff 92       	push	r15
  b2:	0f 93       	push	r16
  b4:	1f 93       	push	r17
  b6:	cf 93       	push	r28
  b8:	df 93       	push	r29
  ba:	cd b7       	in	r28, 0x3d	; 61
  bc:	de b7       	in	r29, 0x3e	; 62
  be:	60 97       	sbiw	r28, 0x10	; 16
  c0:	0f b6       	in	r0, 0x3f	; 63
  c2:	f8 94       	cli
  c4:	de bf       	out	0x3e, r29	; 62
  c6:	0f be       	out	0x3f, r0	; 63
  c8:	cd bf       	out	0x3d, r28	; 61
  ca:	5c 01       	movw	r10, r24
  cc:	fb 01       	movw	r30, r22
  ce:	9c 01       	movw	r18, r24
  d0:	20 56       	subi	r18, 0x60	; 96
  d2:	3f 4f       	sbci	r19, 0xFF	; 255
  d4:	7a 01       	movw	r14, r20
  d6:	60 5f       	subi	r22, 0xF0	; 240
  d8:	7f 4f       	sbci	r23, 0xFF	; 255
  da:	8a 01       	movw	r16, r20

    roundkeys += 160;

    // first round
    for ( i = 0; i < AES_BLOCK_SIZE; ++i ) {
        *(plaintext+i) = *(ciphertext+i) ^ *(roundkeys+i);
  dc:	91 91       	ld	r25, Z+
  de:	d9 01       	movw	r26, r18
  e0:	8d 91       	ld	r24, X+
  e2:	9d 01       	movw	r18, r26
  e4:	89 27       	eor	r24, r25
  e6:	d8 01       	movw	r26, r16
  e8:	8d 93       	st	X+, r24
  ea:	8d 01       	movw	r16, r26
    uint8_t i, j;

    roundkeys += 160;

    // first round
    for ( i = 0; i < AES_BLOCK_SIZE; ++i ) {
  ec:	e6 17       	cp	r30, r22
  ee:	f7 07       	cpc	r31, r23
  f0:	a9 f7       	brne	.-22     	; 0xdc <aes_decrypt_128+0x46>
        *(plaintext+i) = *(ciphertext+i) ^ *(roundkeys+i);
    }
    roundkeys -= 16;
  f2:	65 01       	movw	r12, r10
  f4:	b0 e9       	ldi	r27, 0x90	; 144
  f6:	cb 0e       	add	r12, r27
  f8:	d1 1c       	adc	r13, r1
 *  Row3: s3  s7  s11 s15   >>> 3 bytes
 */
static void inv_shift_rows(uint8_t *state) {
    uint8_t temp;
    // row1
    temp        = *(state+13);
  fa:	fa 01       	movw	r30, r20
  fc:	85 85       	ldd	r24, Z+13	; 0x0d
    *(state+13) = *(state+9);
  fe:	91 85       	ldd	r25, Z+9	; 0x09
 100:	95 87       	std	Z+13, r25	; 0x0d
    *(state+9)  = *(state+5);
 102:	95 81       	ldd	r25, Z+5	; 0x05
 104:	91 87       	std	Z+9, r25	; 0x09
    *(state+5)  = *(state+1); //first bug
 106:	91 81       	ldd	r25, Z+1	; 0x01
 108:	95 83       	std	Z+5, r25	; 0x05
    *(state+1)  = temp;
 10a:	81 83       	std	Z+1, r24	; 0x01
    // row2
    temp        = *(state+14);
 10c:	86 85       	ldd	r24, Z+14	; 0x0e
    *(state+14) = *(state+6);
 10e:	96 81       	ldd	r25, Z+6	; 0x06
 110:	96 87       	std	Z+14, r25	; 0x0e
    *(state+6)  = temp;
 112:	86 83       	std	Z+6, r24	; 0x06
    temp        = *(state+10);
 114:	82 85       	ldd	r24, Z+10	; 0x0a
    *(state+10) = *(state+2);
 116:	92 81       	ldd	r25, Z+2	; 0x02
 118:	92 87       	std	Z+10, r25	; 0x0a
    *(state+2)  = temp;
 11a:	82 83       	std	Z+2, r24	; 0x02
    // row3
    temp        = *(state+3);
 11c:	83 81       	ldd	r24, Z+3	; 0x03
    *(state+3)  = *(state+7);
 11e:	97 81       	ldd	r25, Z+7	; 0x07
 120:	93 83       	std	Z+3, r25	; 0x03
    *(state+7)  = *(state+11);
 122:	93 85       	ldd	r25, Z+11	; 0x0b
 124:	97 83       	std	Z+7, r25	; 0x07
    *(state+11) = *(state+15);
 126:	97 85       	ldd	r25, Z+15	; 0x0f
 128:	93 87       	std	Z+11, r25	; 0x0b
    *(state+15) = temp;
 12a:	87 87       	std	Z+15, r24	; 0x0f
 12c:	ba 01       	movw	r22, r20
 12e:	60 5f       	subi	r22, 0xF0	; 240
 130:	7f 4f       	sbci	r23, 0xFF	; 255
 132:	da 01       	movw	r26, r20
        *(plaintext+i) = *(ciphertext+i) ^ *(roundkeys+i);
    }
    roundkeys -= 16;
    inv_shift_rows(plaintext);
    for (i = 0; i < AES_BLOCK_SIZE; ++i) {
        *(plaintext+i) = INV_SBOX[*(plaintext+i)];
 134:	ec 91       	ld	r30, X
 136:	f0 e0       	ldi	r31, 0x00	; 0
 138:	e0 5d       	subi	r30, 0xD0	; 208
 13a:	fd 4f       	sbci	r31, 0xFD	; 253
 13c:	80 81       	ld	r24, Z
 13e:	8d 93       	st	X+, r24
    for ( i = 0; i < AES_BLOCK_SIZE; ++i ) {
        *(plaintext+i) = *(ciphertext+i) ^ *(roundkeys+i);
    }
    roundkeys -= 16;
    inv_shift_rows(plaintext);
    for (i = 0; i < AES_BLOCK_SIZE; ++i) {
 140:	a6 17       	cp	r26, r22
 142:	b7 07       	cpc	r27, r23
 144:	b9 f7       	brne	.-18     	; 0x134 <aes_decrypt_128+0x9e>
 146:	8e 01       	movw	r16, r28
 148:	0f 5e       	subi	r16, 0xEF	; 239
 14a:	1f 4f       	sbci	r17, 0xFF	; 255
 * by the polynomial x^8 + x^4 + x^3 + x + 1 = 0
 * We do use mul2(int8_t a) but not mul(uint8_t a, uint8_t b)
 * just in order to get a higher speed.
 */
static inline uint8_t mul2(uint8_t a) {
    return (a & 0x80) ? ( (a<<1) ^ 0x1b) : (a<<1);;
 14c:	0f 2e       	mov	r0, r31
 14e:	fb e1       	ldi	r31, 0x1B	; 27
 150:	9f 2e       	mov	r9, r31
 152:	f0 2d       	mov	r31, r0
 154:	c7 c0       	rjmp	.+398    	; 0x2e4 <aes_decrypt_128+0x24e>

    for (j = 1; j < AES_ROUNDS; ++j) {
        
        // Inverse AddRoundKey
        for ( i = 0; i < AES_BLOCK_SIZE; ++i ) {
            *(tmp+i) = *(plaintext+i) ^ *(roundkeys+i);
 156:	d2 01       	movw	r26, r4
 158:	7d 90       	ld	r7, X+
 15a:	2d 01       	movw	r4, r26
 15c:	dc 01       	movw	r26, r24
 15e:	8d 90       	ld	r8, X+
 160:	cd 01       	movw	r24, r26
 162:	87 24       	eor	r8, r7
 164:	81 92       	st	Z+, r8
    }

    for (j = 1; j < AES_ROUNDS; ++j) {
        
        // Inverse AddRoundKey
        for ( i = 0; i < AES_BLOCK_SIZE; ++i ) {
 166:	0e 17       	cp	r16, r30
 168:	1f 07       	cpc	r17, r31
 16a:	a9 f7       	brne	.-22     	; 0x156 <aes_decrypt_128+0xc0>
 16c:	c7 01       	movw	r24, r14
         * [09 0e 0b 0d] . [s1  s5  s9  s13]
         * [0d 09 0e 0b]   [s2  s6  s10 s14]
         * [0b 0d 09 0e]   [s3  s7  s11 s15]
         */
        for (i = 0; i < AES_BLOCK_SIZE; i+=4) {
            t = tmp[i] ^ tmp[i+1] ^ tmp[i+2] ^ tmp[i+3];
 16e:	f9 01       	movw	r30, r18
 170:	b0 81       	ld	r27, Z
 172:	41 80       	ldd	r4, Z+1	; 0x01
 174:	7b 2e       	mov	r7, r27
 176:	74 24       	eor	r7, r4
 178:	32 80       	ldd	r3, Z+2	; 0x02
 17a:	a3 81       	ldd	r26, Z+3	; 0x03
 17c:	23 2c       	mov	r2, r3
 17e:	2a 26       	eor	r2, r26
 180:	57 2c       	mov	r5, r7
 182:	52 24       	eor	r5, r2
            plaintext[i]   = t ^ tmp[i]   ^ mul2(tmp[i]   ^ tmp[i+1]);
 184:	8b 2e       	mov	r8, r27
 186:	85 24       	eor	r8, r5
 * by the polynomial x^8 + x^4 + x^3 + x + 1 = 0
 * We do use mul2(int8_t a) but not mul(uint8_t a, uint8_t b)
 * just in order to get a higher speed.
 */
static inline uint8_t mul2(uint8_t a) {
    return (a & 0x80) ? ( (a<<1) ^ 0x1b) : (a<<1);;
 188:	77 20       	and	r7, r7
 18a:	24 f4       	brge	.+8      	; 0x194 <aes_decrypt_128+0xfe>
 18c:	e7 2d       	mov	r30, r7
 18e:	ee 0f       	add	r30, r30
 190:	e9 25       	eor	r30, r9
 192:	02 c0       	rjmp	.+4      	; 0x198 <aes_decrypt_128+0x102>
 194:	e7 2d       	mov	r30, r7
 196:	ee 0f       	add	r30, r30
         * [0d 09 0e 0b]   [s2  s6  s10 s14]
         * [0b 0d 09 0e]   [s3  s7  s11 s15]
         */
        for (i = 0; i < AES_BLOCK_SIZE; i+=4) {
            t = tmp[i] ^ tmp[i+1] ^ tmp[i+2] ^ tmp[i+3];
            plaintext[i]   = t ^ tmp[i]   ^ mul2(tmp[i]   ^ tmp[i+1]);
 198:	8e 26       	eor	r8, r30
 19a:	fc 01       	movw	r30, r24
            plaintext[i+1] = t ^ tmp[i+1] ^ mul2(tmp[i+1] ^ tmp[i+2]);
 19c:	74 2c       	mov	r7, r4
 19e:	75 24       	eor	r7, r5
 1a0:	64 2c       	mov	r6, r4
 1a2:	63 24       	eor	r6, r3
 * by the polynomial x^8 + x^4 + x^3 + x + 1 = 0
 * We do use mul2(int8_t a) but not mul(uint8_t a, uint8_t b)
 * just in order to get a higher speed.
 */
static inline uint8_t mul2(uint8_t a) {
    return (a & 0x80) ? ( (a<<1) ^ 0x1b) : (a<<1);;
 1a4:	1c f4       	brge	.+6      	; 0x1ac <aes_decrypt_128+0x116>
 1a6:	66 0c       	add	r6, r6
 1a8:	69 24       	eor	r6, r9
 1aa:	01 c0       	rjmp	.+2      	; 0x1ae <aes_decrypt_128+0x118>
 1ac:	66 0c       	add	r6, r6
         * [0b 0d 09 0e]   [s3  s7  s11 s15]
         */
        for (i = 0; i < AES_BLOCK_SIZE; i+=4) {
            t = tmp[i] ^ tmp[i+1] ^ tmp[i+2] ^ tmp[i+3];
            plaintext[i]   = t ^ tmp[i]   ^ mul2(tmp[i]   ^ tmp[i+1]);
            plaintext[i+1] = t ^ tmp[i+1] ^ mul2(tmp[i+1] ^ tmp[i+2]);
 1ae:	76 24       	eor	r7, r6
            plaintext[i+2] = t ^ tmp[i+2] ^ mul2(tmp[i+2] ^ tmp[i+3]);
 1b0:	63 2c       	mov	r6, r3
 1b2:	65 24       	eor	r6, r5
 * by the polynomial x^8 + x^4 + x^3 + x + 1 = 0
 * We do use mul2(int8_t a) but not mul(uint8_t a, uint8_t b)
 * just in order to get a higher speed.
 */
static inline uint8_t mul2(uint8_t a) {
    return (a & 0x80) ? ( (a<<1) ^ 0x1b) : (a<<1);;
 1b4:	22 20       	and	r2, r2
 1b6:	1c f4       	brge	.+6      	; 0x1be <aes_decrypt_128+0x128>
 1b8:	22 0c       	add	r2, r2
 1ba:	29 24       	eor	r2, r9
 1bc:	01 c0       	rjmp	.+2      	; 0x1c0 <aes_decrypt_128+0x12a>
 1be:	22 0c       	add	r2, r2
         */
        for (i = 0; i < AES_BLOCK_SIZE; i+=4) {
            t = tmp[i] ^ tmp[i+1] ^ tmp[i+2] ^ tmp[i+3];
            plaintext[i]   = t ^ tmp[i]   ^ mul2(tmp[i]   ^ tmp[i+1]);
            plaintext[i+1] = t ^ tmp[i+1] ^ mul2(tmp[i+1] ^ tmp[i+2]);
            plaintext[i+2] = t ^ tmp[i+2] ^ mul2(tmp[i+2] ^ tmp[i+3]);
 1c0:	62 24       	eor	r6, r2
            plaintext[i+3] = t ^ tmp[i+3] ^ mul2(tmp[i+3] ^ tmp[i]);
 1c2:	5a 26       	eor	r5, r26
 1c4:	2b 2e       	mov	r2, r27
 1c6:	2a 26       	eor	r2, r26
 * by the polynomial x^8 + x^4 + x^3 + x + 1 = 0
 * We do use mul2(int8_t a) but not mul(uint8_t a, uint8_t b)
 * just in order to get a higher speed.
 */
static inline uint8_t mul2(uint8_t a) {
    return (a & 0x80) ? ( (a<<1) ^ 0x1b) : (a<<1);;
 1c8:	1c f4       	brge	.+6      	; 0x1d0 <aes_decrypt_128+0x13a>
 1ca:	22 0c       	add	r2, r2
 1cc:	29 24       	eor	r2, r9
 1ce:	01 c0       	rjmp	.+2      	; 0x1d2 <aes_decrypt_128+0x13c>
 1d0:	22 0c       	add	r2, r2
        for (i = 0; i < AES_BLOCK_SIZE; i+=4) {
            t = tmp[i] ^ tmp[i+1] ^ tmp[i+2] ^ tmp[i+3];
            plaintext[i]   = t ^ tmp[i]   ^ mul2(tmp[i]   ^ tmp[i+1]);
            plaintext[i+1] = t ^ tmp[i+1] ^ mul2(tmp[i+1] ^ tmp[i+2]);
            plaintext[i+2] = t ^ tmp[i+2] ^ mul2(tmp[i+2] ^ tmp[i+3]);
            plaintext[i+3] = t ^ tmp[i+3] ^ mul2(tmp[i+3] ^ tmp[i]);
 1d2:	52 24       	eor	r5, r2
            u = mul2(mul2(tmp[i]   ^ tmp[i+2]));
 1d4:	b3 25       	eor	r27, r3
 * by the polynomial x^8 + x^4 + x^3 + x + 1 = 0
 * We do use mul2(int8_t a) but not mul(uint8_t a, uint8_t b)
 * just in order to get a higher speed.
 */
static inline uint8_t mul2(uint8_t a) {
    return (a & 0x80) ? ( (a<<1) ^ 0x1b) : (a<<1);;
 1d6:	1c f4       	brge	.+6      	; 0x1de <aes_decrypt_128+0x148>
 1d8:	bb 0f       	add	r27, r27
 1da:	b9 25       	eor	r27, r9
 1dc:	01 c0       	rjmp	.+2      	; 0x1e0 <aes_decrypt_128+0x14a>
 1de:	bb 0f       	add	r27, r27
 1e0:	bb 23       	and	r27, r27
 1e2:	1c f4       	brge	.+6      	; 0x1ea <aes_decrypt_128+0x154>
 1e4:	bb 0f       	add	r27, r27
 1e6:	b9 25       	eor	r27, r9
 1e8:	01 c0       	rjmp	.+2      	; 0x1ec <aes_decrypt_128+0x156>
 1ea:	bb 0f       	add	r27, r27
            plaintext[i]   = t ^ tmp[i]   ^ mul2(tmp[i]   ^ tmp[i+1]);
            plaintext[i+1] = t ^ tmp[i+1] ^ mul2(tmp[i+1] ^ tmp[i+2]);
            plaintext[i+2] = t ^ tmp[i+2] ^ mul2(tmp[i+2] ^ tmp[i+3]);
            plaintext[i+3] = t ^ tmp[i+3] ^ mul2(tmp[i+3] ^ tmp[i]);
            u = mul2(mul2(tmp[i]   ^ tmp[i+2]));
            v = mul2(mul2(tmp[i+1] ^ tmp[i+3]));
 1ec:	a4 25       	eor	r26, r4
 * by the polynomial x^8 + x^4 + x^3 + x + 1 = 0
 * We do use mul2(int8_t a) but not mul(uint8_t a, uint8_t b)
 * just in order to get a higher speed.
 */
static inline uint8_t mul2(uint8_t a) {
    return (a & 0x80) ? ( (a<<1) ^ 0x1b) : (a<<1);;
 1ee:	1c f4       	brge	.+6      	; 0x1f6 <aes_decrypt_128+0x160>
 1f0:	aa 0f       	add	r26, r26
 1f2:	a9 25       	eor	r26, r9
 1f4:	01 c0       	rjmp	.+2      	; 0x1f8 <aes_decrypt_128+0x162>
 1f6:	aa 0f       	add	r26, r26
 1f8:	aa 23       	and	r26, r26
 1fa:	1c f4       	brge	.+6      	; 0x202 <aes_decrypt_128+0x16c>
 1fc:	aa 0f       	add	r26, r26
 1fe:	a9 25       	eor	r26, r9
 200:	01 c0       	rjmp	.+2      	; 0x204 <aes_decrypt_128+0x16e>
 202:	aa 0f       	add	r26, r26
            plaintext[i+1] = t ^ tmp[i+1] ^ mul2(tmp[i+1] ^ tmp[i+2]);
            plaintext[i+2] = t ^ tmp[i+2] ^ mul2(tmp[i+2] ^ tmp[i+3]);
            plaintext[i+3] = t ^ tmp[i+3] ^ mul2(tmp[i+3] ^ tmp[i]);
            u = mul2(mul2(tmp[i]   ^ tmp[i+2]));
            v = mul2(mul2(tmp[i+1] ^ tmp[i+3]));
            t = mul2(u ^ v);
 204:	4a 2e       	mov	r4, r26
 206:	4b 26       	eor	r4, r27
 * by the polynomial x^8 + x^4 + x^3 + x + 1 = 0
 * We do use mul2(int8_t a) but not mul(uint8_t a, uint8_t b)
 * just in order to get a higher speed.
 */
static inline uint8_t mul2(uint8_t a) {
    return (a & 0x80) ? ( (a<<1) ^ 0x1b) : (a<<1);;
 208:	1c f4       	brge	.+6      	; 0x210 <aes_decrypt_128+0x17a>
 20a:	44 0c       	add	r4, r4
 20c:	49 24       	eor	r4, r9
 20e:	01 c0       	rjmp	.+2      	; 0x212 <aes_decrypt_128+0x17c>
 210:	44 0c       	add	r4, r4
            plaintext[i+2] = t ^ tmp[i+2] ^ mul2(tmp[i+2] ^ tmp[i+3]);
            plaintext[i+3] = t ^ tmp[i+3] ^ mul2(tmp[i+3] ^ tmp[i]);
            u = mul2(mul2(tmp[i]   ^ tmp[i+2]));
            v = mul2(mul2(tmp[i+1] ^ tmp[i+3]));
            t = mul2(u ^ v);
            plaintext[i]   ^= t ^ u;
 212:	b4 25       	eor	r27, r4
 214:	8b 26       	eor	r8, r27
 216:	80 82       	st	Z, r8
            plaintext[i+1] ^= t ^ v;
 218:	a4 25       	eor	r26, r4
 21a:	7a 26       	eor	r7, r26
 21c:	71 82       	std	Z+1, r7	; 0x01
            plaintext[i+2] ^= t ^ u;
 21e:	b6 25       	eor	r27, r6
 220:	b2 83       	std	Z+2, r27	; 0x02
            plaintext[i+3] ^= t ^ v;
 222:	a5 25       	eor	r26, r5
 224:	a3 83       	std	Z+3, r26	; 0x03
 226:	2c 5f       	subi	r18, 0xFC	; 252
 228:	3f 4f       	sbci	r19, 0xFF	; 255
 22a:	04 96       	adiw	r24, 0x04	; 4
         * [0e 0b 0d 09]   [s0  s4  s8  s12]
         * [09 0e 0b 0d] . [s1  s5  s9  s13]
         * [0d 09 0e 0b]   [s2  s6  s10 s14]
         * [0b 0d 09 0e]   [s3  s7  s11 s15]
         */
        for (i = 0; i < AES_BLOCK_SIZE; i+=4) {
 22c:	86 17       	cp	r24, r22
 22e:	97 07       	cpc	r25, r23
 230:	09 f0       	breq	.+2      	; 0x234 <aes_decrypt_128+0x19e>
 232:	9d cf       	rjmp	.-198    	; 0x16e <aes_decrypt_128+0xd8>
 *  Row3: s3  s7  s11 s15   >>> 3 bytes
 */
static void inv_shift_rows(uint8_t *state) {
    uint8_t temp;
    // row1
    temp        = *(state+13);
 234:	da 01       	movw	r26, r20
 236:	1d 96       	adiw	r26, 0x0d	; 13
 238:	8c 91       	ld	r24, X
 23a:	1d 97       	sbiw	r26, 0x0d	; 13
    *(state+13) = *(state+9);
 23c:	19 96       	adiw	r26, 0x09	; 9
 23e:	9c 91       	ld	r25, X
 240:	19 97       	sbiw	r26, 0x09	; 9
 242:	1d 96       	adiw	r26, 0x0d	; 13
 244:	9c 93       	st	X, r25
 246:	1d 97       	sbiw	r26, 0x0d	; 13
    *(state+9)  = *(state+5);
 248:	15 96       	adiw	r26, 0x05	; 5
 24a:	9c 91       	ld	r25, X
 24c:	15 97       	sbiw	r26, 0x05	; 5
 24e:	19 96       	adiw	r26, 0x09	; 9
 250:	9c 93       	st	X, r25
 252:	19 97       	sbiw	r26, 0x09	; 9
    *(state+5)  = *(state+1); //first bug
 254:	11 96       	adiw	r26, 0x01	; 1
 256:	9c 91       	ld	r25, X
 258:	11 97       	sbiw	r26, 0x01	; 1
 25a:	15 96       	adiw	r26, 0x05	; 5
 25c:	9c 93       	st	X, r25
 25e:	15 97       	sbiw	r26, 0x05	; 5
    *(state+1)  = temp;
 260:	11 96       	adiw	r26, 0x01	; 1
 262:	8c 93       	st	X, r24
 264:	11 97       	sbiw	r26, 0x01	; 1
    // row2
    temp        = *(state+14);
 266:	1e 96       	adiw	r26, 0x0e	; 14
 268:	8c 91       	ld	r24, X
 26a:	1e 97       	sbiw	r26, 0x0e	; 14
    *(state+14) = *(state+6);
 26c:	16 96       	adiw	r26, 0x06	; 6
 26e:	9c 91       	ld	r25, X
 270:	16 97       	sbiw	r26, 0x06	; 6
 272:	1e 96       	adiw	r26, 0x0e	; 14
 274:	9c 93       	st	X, r25
 276:	1e 97       	sbiw	r26, 0x0e	; 14
    *(state+6)  = temp;
 278:	16 96       	adiw	r26, 0x06	; 6
 27a:	8c 93       	st	X, r24
 27c:	16 97       	sbiw	r26, 0x06	; 6
    temp        = *(state+10);
 27e:	1a 96       	adiw	r26, 0x0a	; 10
 280:	8c 91       	ld	r24, X
 282:	1a 97       	sbiw	r26, 0x0a	; 10
    *(state+10) = *(state+2);
 284:	12 96       	adiw	r26, 0x02	; 2
 286:	9c 91       	ld	r25, X
 288:	12 97       	sbiw	r26, 0x02	; 2
 28a:	1a 96       	adiw	r26, 0x0a	; 10
 28c:	9c 93       	st	X, r25
 28e:	1a 97       	sbiw	r26, 0x0a	; 10
    *(state+2)  = temp;
 290:	12 96       	adiw	r26, 0x02	; 2
 292:	8c 93       	st	X, r24
 294:	12 97       	sbiw	r26, 0x02	; 2
    // row3
    temp        = *(state+3);
 296:	13 96       	adiw	r26, 0x03	; 3
 298:	8c 91       	ld	r24, X
 29a:	13 97       	sbiw	r26, 0x03	; 3
    *(state+3)  = *(state+7);
 29c:	17 96       	adiw	r26, 0x07	; 7
 29e:	9c 91       	ld	r25, X
 2a0:	17 97       	sbiw	r26, 0x07	; 7
 2a2:	13 96       	adiw	r26, 0x03	; 3
 2a4:	9c 93       	st	X, r25
 2a6:	13 97       	sbiw	r26, 0x03	; 3
    *(state+7)  = *(state+11);
 2a8:	1b 96       	adiw	r26, 0x0b	; 11
 2aa:	9c 91       	ld	r25, X
 2ac:	1b 97       	sbiw	r26, 0x0b	; 11
 2ae:	17 96       	adiw	r26, 0x07	; 7
 2b0:	9c 93       	st	X, r25
 2b2:	17 97       	sbiw	r26, 0x07	; 7
    *(state+11) = *(state+15);
 2b4:	1f 96       	adiw	r26, 0x0f	; 15
 2b6:	9c 91       	ld	r25, X
 2b8:	1f 97       	sbiw	r26, 0x0f	; 15
 2ba:	1b 96       	adiw	r26, 0x0b	; 11
 2bc:	9c 93       	st	X, r25
 2be:	1b 97       	sbiw	r26, 0x0b	; 11
    *(state+15) = temp;
 2c0:	1f 96       	adiw	r26, 0x0f	; 15
 2c2:	8c 93       	st	X, r24
 2c4:	d7 01       	movw	r26, r14
        // Inverse ShiftRows
        inv_shift_rows(plaintext);
        
        // Inverse SubBytes
        for (i = 0; i < AES_BLOCK_SIZE; ++i) {
            *(plaintext+i) = INV_SBOX[*(plaintext+i)];
 2c6:	ec 91       	ld	r30, X
 2c8:	f0 e0       	ldi	r31, 0x00	; 0
 2ca:	e0 5d       	subi	r30, 0xD0	; 208
 2cc:	fd 4f       	sbci	r31, 0xFD	; 253
 2ce:	80 81       	ld	r24, Z
 2d0:	8d 93       	st	X+, r24
        
        // Inverse ShiftRows
        inv_shift_rows(plaintext);
        
        // Inverse SubBytes
        for (i = 0; i < AES_BLOCK_SIZE; ++i) {
 2d2:	a6 17       	cp	r26, r22
 2d4:	b7 07       	cpc	r27, r23
 2d6:	b9 f7       	brne	.-18     	; 0x2c6 <aes_decrypt_128+0x230>
            *(plaintext+i) = INV_SBOX[*(plaintext+i)];
        }

        roundkeys -= 16;
 2d8:	b0 e1       	ldi	r27, 0x10	; 16
 2da:	cb 1a       	sub	r12, r27
 2dc:	d1 08       	sbc	r13, r1
    inv_shift_rows(plaintext);
    for (i = 0; i < AES_BLOCK_SIZE; ++i) {
        *(plaintext+i) = INV_SBOX[*(plaintext+i)];
    }

    for (j = 1; j < AES_ROUNDS; ++j) {
 2de:	ac 14       	cp	r10, r12
 2e0:	bd 04       	cpc	r11, r13
 2e2:	39 f0       	breq	.+14     	; 0x2f2 <aes_decrypt_128+0x25c>
 2e4:	c6 01       	movw	r24, r12
 2e6:	9e 01       	movw	r18, r28
 2e8:	2f 5f       	subi	r18, 0xFF	; 255
 2ea:	3f 4f       	sbci	r19, 0xFF	; 255
    // row3
    temp        = *(state+3);
    *(state+3)  = *(state+7);
    *(state+7)  = *(state+11);
    *(state+11) = *(state+15);
    *(state+15) = temp;
 2ec:	f9 01       	movw	r30, r18
 2ee:	27 01       	movw	r4, r14
 2f0:	32 cf       	rjmp	.-412    	; 0x156 <aes_decrypt_128+0xc0>
 2f2:	f5 01       	movw	r30, r10
 2f4:	80 e1       	ldi	r24, 0x10	; 16
 2f6:	a8 0e       	add	r10, r24
 2f8:	b1 1c       	adc	r11, r1

    }

    // last AddRoundKey
    for ( i = 0; i < AES_BLOCK_SIZE; ++i ) {
        *(plaintext+i) ^= *(roundkeys+i);
 2fa:	91 91       	ld	r25, Z+
 2fc:	d7 01       	movw	r26, r14
 2fe:	2c 91       	ld	r18, X
 300:	92 27       	eor	r25, r18
 302:	9d 93       	st	X+, r25
 304:	7d 01       	movw	r14, r26
        roundkeys -= 16;

    }

    // last AddRoundKey
    for ( i = 0; i < AES_BLOCK_SIZE; ++i ) {
 306:	ae 16       	cp	r10, r30
 308:	bf 06       	cpc	r11, r31
 30a:	b9 f7       	brne	.-18     	; 0x2fa <aes_decrypt_128+0x264>
        *(plaintext+i) ^= *(roundkeys+i);
    }

 30c:	60 96       	adiw	r28, 0x10	; 16
 30e:	0f b6       	in	r0, 0x3f	; 63
 310:	f8 94       	cli
 312:	de bf       	out	0x3e, r29	; 62
 314:	0f be       	out	0x3f, r0	; 63
 316:	cd bf       	out	0x3d, r28	; 61
 318:	df 91       	pop	r29
 31a:	cf 91       	pop	r28
 31c:	1f 91       	pop	r17
 31e:	0f 91       	pop	r16
 320:	ff 90       	pop	r15
 322:	ef 90       	pop	r14
 324:	df 90       	pop	r13
 326:	cf 90       	pop	r12
 328:	bf 90       	pop	r11
 32a:	af 90       	pop	r10
 32c:	9f 90       	pop	r9
 32e:	8f 90       	pop	r8
 330:	7f 90       	pop	r7
 332:	6f 90       	pop	r6
 334:	5f 90       	pop	r5
 336:	4f 90       	pop	r4
 338:	3f 90       	pop	r3
 33a:	2f 90       	pop	r2
 33c:	08 95       	ret

0000033e <aes_encrypt_128>:
    *(state+11) = *(state+7);
    *(state+7)  = *(state+3);
    *(state+3)  = temp;
}

void aes_encrypt_128(const uint8_t *roundkeys, const uint8_t *plaintext, uint8_t *ciphertext) {
 33e:	3f 92       	push	r3
 340:	4f 92       	push	r4
 342:	5f 92       	push	r5
 344:	6f 92       	push	r6
 346:	7f 92       	push	r7
 348:	8f 92       	push	r8
 34a:	9f 92       	push	r9
 34c:	af 92       	push	r10
 34e:	bf 92       	push	r11
 350:	cf 92       	push	r12
 352:	df 92       	push	r13
 354:	ef 92       	push	r14
 356:	ff 92       	push	r15
 358:	0f 93       	push	r16
 35a:	1f 93       	push	r17
 35c:	cf 93       	push	r28
 35e:	df 93       	push	r29
 360:	cd b7       	in	r28, 0x3d	; 61
 362:	de b7       	in	r29, 0x3e	; 62
 364:	62 97       	sbiw	r28, 0x12	; 18
 366:	0f b6       	in	r0, 0x3f	; 63
 368:	f8 94       	cli
 36a:	de bf       	out	0x3e, r29	; 62
 36c:	0f be       	out	0x3f, r0	; 63
 36e:	cd bf       	out	0x3d, r28	; 61
 370:	9a 8b       	std	Y+18, r25	; 0x12
 372:	89 8b       	std	Y+17, r24	; 0x11
 374:	fb 01       	movw	r30, r22
 376:	9c 01       	movw	r18, r24
 378:	7a 01       	movw	r14, r20
 37a:	60 5f       	subi	r22, 0xF0	; 240
 37c:	7f 4f       	sbci	r23, 0xFF	; 255
 37e:	8a 01       	movw	r16, r20
    uint8_t tmp[16], t;
    uint8_t i, j;

    // first AddRoundKey
    for ( i = 0; i < AES_BLOCK_SIZE; ++i ) {
        *(ciphertext+i) = *(plaintext+i) ^ *roundkeys++;
 380:	91 91       	ld	r25, Z+
 382:	d9 01       	movw	r26, r18
 384:	8d 91       	ld	r24, X+
 386:	9d 01       	movw	r18, r26
 388:	89 27       	eor	r24, r25
 38a:	d8 01       	movw	r26, r16
 38c:	8d 93       	st	X+, r24
 38e:	8d 01       	movw	r16, r26

    uint8_t tmp[16], t;
    uint8_t i, j;

    // first AddRoundKey
    for ( i = 0; i < AES_BLOCK_SIZE; ++i ) {
 390:	6e 17       	cp	r22, r30
 392:	7f 07       	cpc	r23, r31
 394:	a9 f7       	brne	.-22     	; 0x380 <aes_encrypt_128+0x42>
 396:	c9 88       	ldd	r12, Y+17	; 0x11
 398:	da 88       	ldd	r13, Y+18	; 0x12
 39a:	b0 e1       	ldi	r27, 0x10	; 16
 39c:	cb 0e       	add	r12, r27
 39e:	d1 1c       	adc	r13, r1
 3a0:	a9 88       	ldd	r10, Y+17	; 0x11
 3a2:	ba 88       	ldd	r11, Y+18	; 0x12
 3a4:	e0 ea       	ldi	r30, 0xA0	; 160
 3a6:	ae 0e       	add	r10, r30
 3a8:	b1 1c       	adc	r11, r1
 3aa:	be 01       	movw	r22, r28
 3ac:	6f 5e       	subi	r22, 0xEF	; 239
 3ae:	7f 4f       	sbci	r23, 0xFF	; 255
 * by the polynomial x^8 + x^4 + x^3 + x + 1 = 0
 * We do use mul2(int8_t a) but not mul(uint8_t a, uint8_t b)
 * just in order to get a higher speed.
 */
static inline uint8_t mul2(uint8_t a) {
    return (a & 0x80) ? ( (a<<1) ^ 0x1b) : (a<<1);
 3b0:	0f 2e       	mov	r0, r31
 3b2:	fb e1       	ldi	r31, 0x1B	; 27
 3b4:	9f 2e       	mov	r9, r31
 3b6:	f0 2d       	mov	r31, r0
 3b8:	8a 01       	movw	r16, r20
 3ba:	00 5f       	subi	r16, 0xF0	; 240
 3bc:	1f 4f       	sbci	r17, 0xFF	; 255
 3be:	78 c0       	rjmp	.+240    	; 0x4b0 <__LOCK_REGION_LENGTH__+0xb0>
    // 9 rounds
    for (j = 1; j < AES_ROUNDS; ++j) {

        // SubBytes
        for (i = 0; i < AES_BLOCK_SIZE; ++i) {
            *(tmp+i) = SBOX[*(ciphertext+i)];
 3c0:	fc 01       	movw	r30, r24
 3c2:	81 90       	ld	r8, Z+
 3c4:	cf 01       	movw	r24, r30
 3c6:	e8 2d       	mov	r30, r8
 3c8:	f0 e0       	ldi	r31, 0x00	; 0
 3ca:	e0 50       	subi	r30, 0x00	; 0
 3cc:	ff 4f       	sbci	r31, 0xFF	; 255
 3ce:	e0 81       	ld	r30, Z
 3d0:	ed 93       	st	X+, r30

    // 9 rounds
    for (j = 1; j < AES_ROUNDS; ++j) {

        // SubBytes
        for (i = 0; i < AES_BLOCK_SIZE; ++i) {
 3d2:	a6 17       	cp	r26, r22
 3d4:	b7 07       	cpc	r27, r23
 3d6:	a1 f7       	brne	.-24     	; 0x3c0 <aes_encrypt_128+0x82>
 *  Row3: s3  s7  s11 s15   <<< 3 bytes
 */
static void shift_rows(uint8_t *state) {
    uint8_t temp;
    // row1
    temp        = *(state+1);
 3d8:	8a 81       	ldd	r24, Y+2	; 0x02
    *(state+1)  = *(state+5);
 3da:	9e 81       	ldd	r25, Y+6	; 0x06
 3dc:	9a 83       	std	Y+2, r25	; 0x02
    *(state+5)  = *(state+9);
 3de:	9a 85       	ldd	r25, Y+10	; 0x0a
 3e0:	9e 83       	std	Y+6, r25	; 0x06
    *(state+9)  = *(state+13);
 3e2:	9e 85       	ldd	r25, Y+14	; 0x0e
 3e4:	9a 87       	std	Y+10, r25	; 0x0a
    *(state+13) = temp;
 3e6:	8e 87       	std	Y+14, r24	; 0x0e
    // row2
    temp        = *(state+2);
 3e8:	8b 81       	ldd	r24, Y+3	; 0x03
    *(state+2)  = *(state+10);
 3ea:	9b 85       	ldd	r25, Y+11	; 0x0b
 3ec:	9b 83       	std	Y+3, r25	; 0x03
    *(state+10) = temp;
 3ee:	8b 87       	std	Y+11, r24	; 0x0b
    temp        = *(state+6);
 3f0:	8f 81       	ldd	r24, Y+7	; 0x07
    *(state+6)  = *(state+14);
 3f2:	9f 85       	ldd	r25, Y+15	; 0x0f
 3f4:	9f 83       	std	Y+7, r25	; 0x07
    *(state+14) = temp;
 3f6:	8f 87       	std	Y+15, r24	; 0x0f
    // row3
    temp        = *(state+15);
 3f8:	88 89       	ldd	r24, Y+16	; 0x10
    *(state+15) = *(state+11);
 3fa:	9c 85       	ldd	r25, Y+12	; 0x0c
 3fc:	98 8b       	std	Y+16, r25	; 0x10
    *(state+11) = *(state+7);
 3fe:	98 85       	ldd	r25, Y+8	; 0x08
 400:	9c 87       	std	Y+12, r25	; 0x0c
    *(state+7)  = *(state+3);
 402:	9c 81       	ldd	r25, Y+4	; 0x04
 404:	98 87       	std	Y+8, r25	; 0x08
    *(state+3)  = temp;
 406:	8c 83       	std	Y+4, r24	; 0x04
 408:	f7 01       	movw	r30, r14
         * [01 02 03 01] . [s1  s5  s9  s13]
         * [01 01 02 03]   [s2  s6  s10 s14]
         * [03 01 01 02]   [s3  s7  s11 s15]
         */
        for (i = 0; i < AES_BLOCK_SIZE; i+=4)  {
            t = tmp[i] ^ tmp[i+1] ^ tmp[i+2] ^ tmp[i+3];
 40a:	d9 01       	movw	r26, r18
 40c:	8c 91       	ld	r24, X
 40e:	11 96       	adiw	r26, 0x01	; 1
 410:	5c 90       	ld	r5, X
 412:	11 97       	sbiw	r26, 0x01	; 1
 414:	88 2e       	mov	r8, r24
 416:	85 24       	eor	r8, r5
 418:	12 96       	adiw	r26, 0x02	; 2
 41a:	6c 90       	ld	r6, X
 41c:	12 97       	sbiw	r26, 0x02	; 2
 41e:	13 96       	adiw	r26, 0x03	; 3
 420:	4c 90       	ld	r4, X
 422:	96 2d       	mov	r25, r6
 424:	94 25       	eor	r25, r4
 426:	78 2c       	mov	r7, r8
 428:	79 26       	eor	r7, r25
 * by the polynomial x^8 + x^4 + x^3 + x + 1 = 0
 * We do use mul2(int8_t a) but not mul(uint8_t a, uint8_t b)
 * just in order to get a higher speed.
 */
static inline uint8_t mul2(uint8_t a) {
    return (a & 0x80) ? ( (a<<1) ^ 0x1b) : (a<<1);
 42a:	88 20       	and	r8, r8
 42c:	1c f4       	brge	.+6      	; 0x434 <__LOCK_REGION_LENGTH__+0x34>
 42e:	88 0c       	add	r8, r8
 430:	89 24       	eor	r8, r9
 432:	01 c0       	rjmp	.+2      	; 0x436 <__LOCK_REGION_LENGTH__+0x36>
 434:	88 0c       	add	r8, r8
 436:	df 01       	movw	r26, r30
         * [01 01 02 03]   [s2  s6  s10 s14]
         * [03 01 01 02]   [s3  s7  s11 s15]
         */
        for (i = 0; i < AES_BLOCK_SIZE; i+=4)  {
            t = tmp[i] ^ tmp[i+1] ^ tmp[i+2] ^ tmp[i+3];
            ciphertext[i]   = mul2(tmp[i]   ^ tmp[i+1]) ^ tmp[i]   ^ t;
 438:	38 2e       	mov	r3, r24
 43a:	37 24       	eor	r3, r7
 43c:	83 24       	eor	r8, r3
 43e:	80 82       	st	Z, r8
            ciphertext[i+1] = mul2(tmp[i+1] ^ tmp[i+2]) ^ tmp[i+1] ^ t;
 440:	85 2c       	mov	r8, r5
 442:	86 24       	eor	r8, r6
 * by the polynomial x^8 + x^4 + x^3 + x + 1 = 0
 * We do use mul2(int8_t a) but not mul(uint8_t a, uint8_t b)
 * just in order to get a higher speed.
 */
static inline uint8_t mul2(uint8_t a) {
    return (a & 0x80) ? ( (a<<1) ^ 0x1b) : (a<<1);
 444:	1c f4       	brge	.+6      	; 0x44c <__LOCK_REGION_LENGTH__+0x4c>
 446:	88 0c       	add	r8, r8
 448:	89 24       	eor	r8, r9
 44a:	01 c0       	rjmp	.+2      	; 0x44e <__LOCK_REGION_LENGTH__+0x4e>
 44c:	88 0c       	add	r8, r8
         * [03 01 01 02]   [s3  s7  s11 s15]
         */
        for (i = 0; i < AES_BLOCK_SIZE; i+=4)  {
            t = tmp[i] ^ tmp[i+1] ^ tmp[i+2] ^ tmp[i+3];
            ciphertext[i]   = mul2(tmp[i]   ^ tmp[i+1]) ^ tmp[i]   ^ t;
            ciphertext[i+1] = mul2(tmp[i+1] ^ tmp[i+2]) ^ tmp[i+1] ^ t;
 44e:	57 24       	eor	r5, r7
 450:	58 24       	eor	r5, r8
 452:	11 96       	adiw	r26, 0x01	; 1
 454:	5c 92       	st	X, r5
 456:	11 97       	sbiw	r26, 0x01	; 1
 * by the polynomial x^8 + x^4 + x^3 + x + 1 = 0
 * We do use mul2(int8_t a) but not mul(uint8_t a, uint8_t b)
 * just in order to get a higher speed.
 */
static inline uint8_t mul2(uint8_t a) {
    return (a & 0x80) ? ( (a<<1) ^ 0x1b) : (a<<1);
 458:	99 23       	and	r25, r25
 45a:	1c f4       	brge	.+6      	; 0x462 <__LOCK_REGION_LENGTH__+0x62>
 45c:	99 0f       	add	r25, r25
 45e:	99 25       	eor	r25, r9
 460:	01 c0       	rjmp	.+2      	; 0x464 <__LOCK_REGION_LENGTH__+0x64>
 462:	99 0f       	add	r25, r25
         */
        for (i = 0; i < AES_BLOCK_SIZE; i+=4)  {
            t = tmp[i] ^ tmp[i+1] ^ tmp[i+2] ^ tmp[i+3];
            ciphertext[i]   = mul2(tmp[i]   ^ tmp[i+1]) ^ tmp[i]   ^ t;
            ciphertext[i+1] = mul2(tmp[i+1] ^ tmp[i+2]) ^ tmp[i+1] ^ t;
            ciphertext[i+2] = mul2(tmp[i+2] ^ tmp[i+3]) ^ tmp[i+2] ^ t;
 464:	67 24       	eor	r6, r7
 466:	69 26       	eor	r6, r25
 468:	12 96       	adiw	r26, 0x02	; 2
 46a:	6c 92       	st	X, r6
 46c:	12 97       	sbiw	r26, 0x02	; 2
            ciphertext[i+3] = mul2(tmp[i+3] ^ tmp[i]  ) ^ tmp[i+3] ^ t;
 46e:	84 25       	eor	r24, r4
 * by the polynomial x^8 + x^4 + x^3 + x + 1 = 0
 * We do use mul2(int8_t a) but not mul(uint8_t a, uint8_t b)
 * just in order to get a higher speed.
 */
static inline uint8_t mul2(uint8_t a) {
    return (a & 0x80) ? ( (a<<1) ^ 0x1b) : (a<<1);
 470:	1c f4       	brge	.+6      	; 0x478 <__LOCK_REGION_LENGTH__+0x78>
 472:	88 0f       	add	r24, r24
 474:	89 25       	eor	r24, r9
 476:	01 c0       	rjmp	.+2      	; 0x47a <__LOCK_REGION_LENGTH__+0x7a>
 478:	88 0f       	add	r24, r24
        for (i = 0; i < AES_BLOCK_SIZE; i+=4)  {
            t = tmp[i] ^ tmp[i+1] ^ tmp[i+2] ^ tmp[i+3];
            ciphertext[i]   = mul2(tmp[i]   ^ tmp[i+1]) ^ tmp[i]   ^ t;
            ciphertext[i+1] = mul2(tmp[i+1] ^ tmp[i+2]) ^ tmp[i+1] ^ t;
            ciphertext[i+2] = mul2(tmp[i+2] ^ tmp[i+3]) ^ tmp[i+2] ^ t;
            ciphertext[i+3] = mul2(tmp[i+3] ^ tmp[i]  ) ^ tmp[i+3] ^ t;
 47a:	74 24       	eor	r7, r4
 47c:	87 25       	eor	r24, r7
 47e:	13 96       	adiw	r26, 0x03	; 3
 480:	8c 93       	st	X, r24
 482:	2c 5f       	subi	r18, 0xFC	; 252
 484:	3f 4f       	sbci	r19, 0xFF	; 255
 486:	34 96       	adiw	r30, 0x04	; 4
         * [02 03 01 01]   [s0  s4  s8  s12]
         * [01 02 03 01] . [s1  s5  s9  s13]
         * [01 01 02 03]   [s2  s6  s10 s14]
         * [03 01 01 02]   [s3  s7  s11 s15]
         */
        for (i = 0; i < AES_BLOCK_SIZE; i+=4)  {
 488:	62 17       	cp	r22, r18
 48a:	73 07       	cpc	r23, r19
 48c:	09 f0       	breq	.+2      	; 0x490 <__LOCK_REGION_LENGTH__+0x90>
 48e:	bd cf       	rjmp	.-134    	; 0x40a <__LOCK_REGION_LENGTH__+0xa>
 490:	d6 01       	movw	r26, r12
 492:	c8 01       	movw	r24, r16
 494:	f7 01       	movw	r30, r14
            ciphertext[i+3] = mul2(tmp[i+3] ^ tmp[i]  ) ^ tmp[i+3] ^ t;
        }

        // AddRoundKey
        for ( i = 0; i < AES_BLOCK_SIZE; ++i ) {
            *(ciphertext+i) ^= *roundkeys++;
 496:	2d 91       	ld	r18, X+
 498:	30 81       	ld	r19, Z
 49a:	23 27       	eor	r18, r19
 49c:	21 93       	st	Z+, r18
            ciphertext[i+2] = mul2(tmp[i+2] ^ tmp[i+3]) ^ tmp[i+2] ^ t;
            ciphertext[i+3] = mul2(tmp[i+3] ^ tmp[i]  ) ^ tmp[i+3] ^ t;
        }

        // AddRoundKey
        for ( i = 0; i < AES_BLOCK_SIZE; ++i ) {
 49e:	e0 17       	cp	r30, r16
 4a0:	f1 07       	cpc	r31, r17
 4a2:	c9 f7       	brne	.-14     	; 0x496 <__LOCK_REGION_LENGTH__+0x96>
 4a4:	b0 e1       	ldi	r27, 0x10	; 16
 4a6:	cb 0e       	add	r12, r27
 4a8:	d1 1c       	adc	r13, r1
    for ( i = 0; i < AES_BLOCK_SIZE; ++i ) {
        *(ciphertext+i) = *(plaintext+i) ^ *roundkeys++;
    }

    // 9 rounds
    for (j = 1; j < AES_ROUNDS; ++j) {
 4aa:	ac 14       	cp	r10, r12
 4ac:	bd 04       	cpc	r11, r13
 4ae:	31 f0       	breq	.+12     	; 0x4bc <__LOCK_REGION_LENGTH__+0xbc>
 4b0:	9e 01       	movw	r18, r28
 4b2:	2f 5f       	subi	r18, 0xFF	; 255
 4b4:	3f 4f       	sbci	r19, 0xFF	; 255
    *(state+11) = *(state+7);
    *(state+7)  = *(state+3);
    *(state+3)  = temp;
}

void aes_encrypt_128(const uint8_t *roundkeys, const uint8_t *plaintext, uint8_t *ciphertext) {
 4b6:	d9 01       	movw	r26, r18
 4b8:	c7 01       	movw	r24, r14
 4ba:	82 cf       	rjmp	.-252    	; 0x3c0 <aes_encrypt_128+0x82>
 4bc:	da 01       	movw	r26, r20

    }
    
    // last round
    for (i = 0; i < AES_BLOCK_SIZE; ++i) {
        *(ciphertext+i) = SBOX[*(ciphertext+i)];
 4be:	ec 91       	ld	r30, X
 4c0:	f0 e0       	ldi	r31, 0x00	; 0
 4c2:	e0 50       	subi	r30, 0x00	; 0
 4c4:	ff 4f       	sbci	r31, 0xFF	; 255
 4c6:	20 81       	ld	r18, Z
 4c8:	2d 93       	st	X+, r18
        }

    }
    
    // last round
    for (i = 0; i < AES_BLOCK_SIZE; ++i) {
 4ca:	a8 17       	cp	r26, r24
 4cc:	b9 07       	cpc	r27, r25
 4ce:	b9 f7       	brne	.-18     	; 0x4be <__LOCK_REGION_LENGTH__+0xbe>
 *  Row3: s3  s7  s11 s15   <<< 3 bytes
 */
static void shift_rows(uint8_t *state) {
    uint8_t temp;
    // row1
    temp        = *(state+1);
 4d0:	fa 01       	movw	r30, r20
 4d2:	81 81       	ldd	r24, Z+1	; 0x01
    *(state+1)  = *(state+5);
 4d4:	95 81       	ldd	r25, Z+5	; 0x05
 4d6:	91 83       	std	Z+1, r25	; 0x01
    *(state+5)  = *(state+9);
 4d8:	91 85       	ldd	r25, Z+9	; 0x09
 4da:	95 83       	std	Z+5, r25	; 0x05
    *(state+9)  = *(state+13);
 4dc:	95 85       	ldd	r25, Z+13	; 0x0d
 4de:	91 87       	std	Z+9, r25	; 0x09
    *(state+13) = temp;
 4e0:	85 87       	std	Z+13, r24	; 0x0d
    // row2
    temp        = *(state+2);
 4e2:	82 81       	ldd	r24, Z+2	; 0x02
    *(state+2)  = *(state+10);
 4e4:	92 85       	ldd	r25, Z+10	; 0x0a
 4e6:	92 83       	std	Z+2, r25	; 0x02
    *(state+10) = temp;
 4e8:	82 87       	std	Z+10, r24	; 0x0a
    temp        = *(state+6);
 4ea:	86 81       	ldd	r24, Z+6	; 0x06
    *(state+6)  = *(state+14);
 4ec:	96 85       	ldd	r25, Z+14	; 0x0e
 4ee:	96 83       	std	Z+6, r25	; 0x06
    *(state+14) = temp;
 4f0:	86 87       	std	Z+14, r24	; 0x0e
    // row3
    temp        = *(state+15);
 4f2:	87 85       	ldd	r24, Z+15	; 0x0f
    *(state+15) = *(state+11);
 4f4:	93 85       	ldd	r25, Z+11	; 0x0b
 4f6:	97 87       	std	Z+15, r25	; 0x0f
    *(state+11) = *(state+7);
 4f8:	97 81       	ldd	r25, Z+7	; 0x07
 4fa:	93 87       	std	Z+11, r25	; 0x0b
    *(state+7)  = *(state+3);
 4fc:	93 81       	ldd	r25, Z+3	; 0x03
 4fe:	97 83       	std	Z+7, r25	; 0x07
    *(state+3)  = temp;
 500:	83 83       	std	Z+3, r24	; 0x03
 502:	f5 01       	movw	r30, r10
 504:	49 89       	ldd	r20, Y+17	; 0x11
 506:	5a 89       	ldd	r21, Y+18	; 0x12
 508:	40 55       	subi	r20, 0x50	; 80
 50a:	5f 4f       	sbci	r21, 0xFF	; 255
    for (i = 0; i < AES_BLOCK_SIZE; ++i) {
        *(ciphertext+i) = SBOX[*(ciphertext+i)];
    }
    shift_rows(ciphertext);
    for ( i = 0; i < AES_BLOCK_SIZE; ++i ) {
        *(ciphertext+i) ^= *roundkeys++;
 50c:	91 91       	ld	r25, Z+
 50e:	d7 01       	movw	r26, r14
 510:	2c 91       	ld	r18, X
 512:	92 27       	eor	r25, r18
 514:	9d 93       	st	X+, r25
 516:	7d 01       	movw	r14, r26
    // last round
    for (i = 0; i < AES_BLOCK_SIZE; ++i) {
        *(ciphertext+i) = SBOX[*(ciphertext+i)];
    }
    shift_rows(ciphertext);
    for ( i = 0; i < AES_BLOCK_SIZE; ++i ) {
 518:	4e 17       	cp	r20, r30
 51a:	5f 07       	cpc	r21, r31
 51c:	b9 f7       	brne	.-18     	; 0x50c <__LOCK_REGION_LENGTH__+0x10c>
        *(ciphertext+i) ^= *roundkeys++;
    }

}
 51e:	62 96       	adiw	r28, 0x12	; 18
 520:	0f b6       	in	r0, 0x3f	; 63
 522:	f8 94       	cli
 524:	de bf       	out	0x3e, r29	; 62
 526:	0f be       	out	0x3f, r0	; 63
 528:	cd bf       	out	0x3d, r28	; 61
 52a:	df 91       	pop	r29
 52c:	cf 91       	pop	r28
 52e:	1f 91       	pop	r17
 530:	0f 91       	pop	r16
 532:	ff 90       	pop	r15
 534:	ef 90       	pop	r14
 536:	df 90       	pop	r13
 538:	cf 90       	pop	r12
 53a:	bf 90       	pop	r11
 53c:	af 90       	pop	r10
 53e:	9f 90       	pop	r9
 540:	8f 90       	pop	r8
 542:	7f 90       	pop	r7
 544:	6f 90       	pop	r6
 546:	5f 90       	pop	r5
 548:	4f 90       	pop	r4
 54a:	3f 90       	pop	r3
 54c:	08 95       	ret

0000054e <aes_key_schedule_128>:
#include "aes_encrypt.h"
/*
 * round constants
 */
static uint8_t RC[8] = {0x01, 0x02, 0x04, 0x08, 0x10, 0x20, 0x40, 0x80, 0x1b, 0x36};
void aes_key_schedule_128(uint8_t *key, uint8_t *roundkeys) {
 54e:	af 92       	push	r10
 550:	bf 92       	push	r11
 552:	df 92       	push	r13
 554:	ef 92       	push	r14
 556:	ff 92       	push	r15
 558:	0f 93       	push	r16
 55a:	1f 93       	push	r17
 55c:	cf 93       	push	r28
 55e:	df 93       	push	r29
 560:	ec 01       	movw	r28, r24
 562:	db 01       	movw	r26, r22
 564:	9b 01       	movw	r18, r22
 566:	20 5f       	subi	r18, 0xF0	; 240
 568:	3f 4f       	sbci	r19, 0xFF	; 255
 56a:	fb 01       	movw	r30, r22
    uint8_t *last4bytes; // point to the last 4 bytes of one round
    uint8_t *lastround;
    uint8_t i;

    for (i = 0; i < 16; ++i) {
        *roundkeys++ = *key++;
 56c:	89 91       	ld	r24, Y+
 56e:	81 93       	st	Z+, r24
    uint8_t temp[4];
    uint8_t *last4bytes; // point to the last 4 bytes of one round
    uint8_t *lastround;
    uint8_t i;

    for (i = 0; i < 16; ++i) {
 570:	e2 17       	cp	r30, r18
 572:	f3 07       	cpc	r31, r19
 574:	d9 f7       	brne	.-10     	; 0x56c <aes_key_schedule_128+0x1e>
        *roundkeys++ = *key++;
    }

    last4bytes = roundkeys-4;
 576:	fb 01       	movw	r30, r22
 578:	3c 96       	adiw	r30, 0x0c	; 12
 57a:	0f 2e       	mov	r0, r31
 57c:	f0 e3       	ldi	r31, 0x30	; 48
 57e:	af 2e       	mov	r10, r31
 580:	f3 e0       	ldi	r31, 0x03	; 3
 582:	bf 2e       	mov	r11, r31
 584:	f0 2d       	mov	r31, r0
 586:	64 55       	subi	r22, 0x54	; 84
 588:	7f 4f       	sbci	r23, 0xFF	; 255
    for (i = 0; i < AES_ROUNDS; ++i) {
        // k0-k3 for next round
        temp[3] = SBOX[*last4bytes++];
 58a:	d0 80       	ld	r13, Z
 58c:	8d 2d       	mov	r24, r13
 58e:	90 e0       	ldi	r25, 0x00	; 0
 590:	80 50       	subi	r24, 0x00	; 0
 592:	9f 4f       	sbci	r25, 0xFF	; 255
 594:	ec 01       	movw	r28, r24
 596:	48 81       	ld	r20, Y
        temp[0] = SBOX[*last4bytes++];
 598:	e1 80       	ldd	r14, Z+1	; 0x01
        temp[1] = SBOX[*last4bytes++];
 59a:	f2 80       	ldd	r15, Z+2	; 0x02
 59c:	8f 2d       	mov	r24, r15
 59e:	90 e0       	ldi	r25, 0x00	; 0
 5a0:	80 50       	subi	r24, 0x00	; 0
 5a2:	9f 4f       	sbci	r25, 0xFF	; 255
 5a4:	ec 01       	movw	r28, r24
 5a6:	28 81       	ld	r18, Y
        temp[2] = SBOX[*last4bytes++];
 5a8:	03 81       	ldd	r16, Z+3	; 0x03
 5aa:	10 e0       	ldi	r17, 0x00	; 0
 5ac:	00 50       	subi	r16, 0x00	; 0
 5ae:	1f 4f       	sbci	r17, 0xFF	; 255
 5b0:	e8 01       	movw	r28, r16
 5b2:	58 81       	ld	r21, Y
        temp[0] ^= RC[i];
 5b4:	e5 01       	movw	r28, r10
 5b6:	39 91       	ld	r19, Y+
 5b8:	5e 01       	movw	r10, r28
        lastround = roundkeys-16;
        *roundkeys++ = temp[0] ^ *lastround++;
 5ba:	9c 91       	ld	r25, X
 5bc:	39 27       	eor	r19, r25

    last4bytes = roundkeys-4;
    for (i = 0; i < AES_ROUNDS; ++i) {
        // k0-k3 for next round
        temp[3] = SBOX[*last4bytes++];
        temp[0] = SBOX[*last4bytes++];
 5be:	0e 2d       	mov	r16, r14
 5c0:	10 e0       	ldi	r17, 0x00	; 0
 5c2:	00 50       	subi	r16, 0x00	; 0
 5c4:	1f 4f       	sbci	r17, 0xFF	; 255
        temp[1] = SBOX[*last4bytes++];
        temp[2] = SBOX[*last4bytes++];
        temp[0] ^= RC[i];
        lastround = roundkeys-16;
        *roundkeys++ = temp[0] ^ *lastround++;
 5c6:	e8 01       	movw	r28, r16
 5c8:	98 81       	ld	r25, Y
 5ca:	39 27       	eor	r19, r25
 5cc:	34 83       	std	Z+4, r19	; 0x04
        *roundkeys++ = temp[1] ^ *lastround++;
 5ce:	11 96       	adiw	r26, 0x01	; 1
 5d0:	9c 91       	ld	r25, X
 5d2:	11 97       	sbiw	r26, 0x01	; 1
 5d4:	29 27       	eor	r18, r25
 5d6:	25 83       	std	Z+5, r18	; 0x05
        *roundkeys++ = temp[2] ^ *lastround++;
 5d8:	12 96       	adiw	r26, 0x02	; 2
 5da:	8c 91       	ld	r24, X
 5dc:	12 97       	sbiw	r26, 0x02	; 2
 5de:	85 27       	eor	r24, r21
 5e0:	86 83       	std	Z+6, r24	; 0x06
        *roundkeys++ = temp[3] ^ *lastround++;
 5e2:	13 96       	adiw	r26, 0x03	; 3
 5e4:	9c 91       	ld	r25, X
 5e6:	13 97       	sbiw	r26, 0x03	; 3
 5e8:	49 27       	eor	r20, r25
 5ea:	47 83       	std	Z+7, r20	; 0x07
        // k4-k7 for next round        
        *roundkeys++ = *last4bytes++ ^ *lastround++;
 5ec:	14 96       	adiw	r26, 0x04	; 4
 5ee:	9c 91       	ld	r25, X
 5f0:	14 97       	sbiw	r26, 0x04	; 4
 5f2:	03 2f       	mov	r16, r19
 5f4:	09 27       	eor	r16, r25
 5f6:	00 87       	std	Z+8, r16	; 0x08
        *roundkeys++ = *last4bytes++ ^ *lastround++;
 5f8:	15 96       	adiw	r26, 0x05	; 5
 5fa:	9c 91       	ld	r25, X
 5fc:	15 97       	sbiw	r26, 0x05	; 5
 5fe:	12 2f       	mov	r17, r18
 600:	19 27       	eor	r17, r25
 602:	11 87       	std	Z+9, r17	; 0x09
        *roundkeys++ = *last4bytes++ ^ *lastround++;
 604:	16 96       	adiw	r26, 0x06	; 6
 606:	9c 91       	ld	r25, X
 608:	16 97       	sbiw	r26, 0x06	; 6
 60a:	58 2f       	mov	r21, r24
 60c:	59 27       	eor	r21, r25
 60e:	52 87       	std	Z+10, r21	; 0x0a
        *roundkeys++ = *last4bytes++ ^ *lastround++;
 610:	17 96       	adiw	r26, 0x07	; 7
 612:	9c 91       	ld	r25, X
 614:	17 97       	sbiw	r26, 0x07	; 7
 616:	49 27       	eor	r20, r25
 618:	43 87       	std	Z+11, r20	; 0x0b
        // k8-k11 for next round
        *roundkeys++ = *last4bytes++ ^ *lastround++;
 61a:	18 96       	adiw	r26, 0x08	; 8
 61c:	9c 91       	ld	r25, X
 61e:	18 97       	sbiw	r26, 0x08	; 8
 620:	30 2f       	mov	r19, r16
 622:	39 27       	eor	r19, r25
 624:	34 87       	std	Z+12, r19	; 0x0c
        *roundkeys++ = *last4bytes++ ^ *lastround++;
 626:	19 96       	adiw	r26, 0x09	; 9
 628:	9c 91       	ld	r25, X
 62a:	19 97       	sbiw	r26, 0x09	; 9
 62c:	21 2f       	mov	r18, r17
 62e:	29 27       	eor	r18, r25
 630:	25 87       	std	Z+13, r18	; 0x0d
        *roundkeys++ = *last4bytes++ ^ *lastround++;
 632:	1a 96       	adiw	r26, 0x0a	; 10
 634:	9c 91       	ld	r25, X
 636:	1a 97       	sbiw	r26, 0x0a	; 10
 638:	85 2f       	mov	r24, r21
 63a:	89 27       	eor	r24, r25
 63c:	86 87       	std	Z+14, r24	; 0x0e
        *roundkeys++ = *last4bytes++ ^ *lastround++;
 63e:	1b 96       	adiw	r26, 0x0b	; 11
 640:	9c 91       	ld	r25, X
 642:	1b 97       	sbiw	r26, 0x0b	; 11
 644:	49 27       	eor	r20, r25
 646:	47 87       	std	Z+15, r20	; 0x0f
        // k12-k15 for next round
        *roundkeys++ = *last4bytes++ ^ *lastround++;
 648:	3d 25       	eor	r19, r13
 64a:	30 8b       	std	Z+16, r19	; 0x10
        *roundkeys++ = *last4bytes++ ^ *lastround++;
 64c:	2e 25       	eor	r18, r14
 64e:	21 8b       	std	Z+17, r18	; 0x11
        *roundkeys++ = *last4bytes++ ^ *lastround++;
 650:	8f 25       	eor	r24, r15
 652:	82 8b       	std	Z+18, r24	; 0x12
 654:	70 96       	adiw	r30, 0x10	; 16
        *roundkeys++ = *last4bytes++ ^ *lastround++;
 656:	5b 96       	adiw	r26, 0x1b	; 27
 658:	9c 91       	ld	r25, X
 65a:	5b 97       	sbiw	r26, 0x1b	; 27
 65c:	1f 96       	adiw	r26, 0x0f	; 15
 65e:	8c 91       	ld	r24, X
 660:	1f 97       	sbiw	r26, 0x0f	; 15
 662:	89 27       	eor	r24, r25
 664:	83 83       	std	Z+3, r24	; 0x03
 666:	50 96       	adiw	r26, 0x10	; 16
    for (i = 0; i < 16; ++i) {
        *roundkeys++ = *key++;
    }

    last4bytes = roundkeys-4;
    for (i = 0; i < AES_ROUNDS; ++i) {
 668:	6e 17       	cp	r22, r30
 66a:	7f 07       	cpc	r23, r31
 66c:	09 f0       	breq	.+2      	; 0x670 <aes_key_schedule_128+0x122>
 66e:	8d cf       	rjmp	.-230    	; 0x58a <aes_key_schedule_128+0x3c>
        *roundkeys++ = *last4bytes++ ^ *lastround++;
        *roundkeys++ = *last4bytes++ ^ *lastround++;
        *roundkeys++ = *last4bytes++ ^ *lastround++;
        *roundkeys++ = *last4bytes++ ^ *lastround++;
    }
}
 670:	df 91       	pop	r29
 672:	cf 91       	pop	r28
 674:	1f 91       	pop	r17
 676:	0f 91       	pop	r16
 678:	ff 90       	pop	r15
 67a:	ef 90       	pop	r14
 67c:	df 90       	pop	r13
 67e:	bf 90       	pop	r11
 680:	af 90       	pop	r10
 682:	08 95       	ret

00000684 <main>:
#include "aes_decrypt.h"
#include "aes_encrypt.h"
#include "aes_schedule.h"


int main(int argc, char *argv[]) {
 684:	cf 93       	push	r28
 686:	df 93       	push	r29
 688:	cd b7       	in	r28, 0x3d	; 61
 68a:	de b7       	in	r29, 0x3e	; 62
 68c:	c0 5f       	subi	r28, 0xF0	; 240
 68e:	d1 09       	sbc	r29, r1
 690:	0f b6       	in	r0, 0x3f	; 63
 692:	f8 94       	cli
 694:	de bf       	out	0x3e, r29	; 62
 696:	0f be       	out	0x3f, r0	; 63
 698:	cd bf       	out	0x3d, r28	; 61

	uint8_t i;

	/* 128 bit key */
	 uint8_t key[] = {
 69a:	80 e1       	ldi	r24, 0x10	; 16
 69c:	e0 e0       	ldi	r30, 0x00	; 0
 69e:	f2 e0       	ldi	r31, 0x02	; 2
 6a0:	de 01       	movw	r26, r28
 6a2:	11 96       	adiw	r26, 0x01	; 1
 6a4:	01 90       	ld	r0, Z+
 6a6:	0d 92       	st	X+, r0
 6a8:	8a 95       	dec	r24
 6aa:	e1 f7       	brne	.-8      	; 0x6a4 <main+0x20>
		0x00, 0x01, 0x02, 0x03, 0x04, 0x05, 0x06, 0x07,
		0x08, 0x09, 0x0a, 0x0b, 0x0c, 0x0d, 0x0e, 0x0f, 

	};

	uint8_t plaintext[] = {
 6ac:	80 e1       	ldi	r24, 0x10	; 16
 6ae:	e0 e1       	ldi	r30, 0x10	; 16
 6b0:	f2 e0       	ldi	r31, 0x02	; 2
 6b2:	de 01       	movw	r26, r28
 6b4:	51 96       	adiw	r26, 0x11	; 17
 6b6:	01 90       	ld	r0, Z+
 6b8:	0d 92       	st	X+, r0
 6ba:	8a 95       	dec	r24
 6bc:	e1 f7       	brne	.-8      	; 0x6b6 <main+0x32>
	};

 
	uint8_t ciphertext[AES_BLOCK_SIZE];

	uint8_t const_cipher[AES_BLOCK_SIZE] = {
 6be:	80 e1       	ldi	r24, 0x10	; 16
 6c0:	e0 e2       	ldi	r30, 0x20	; 32
 6c2:	f2 e0       	ldi	r31, 0x02	; 2
 6c4:	de 01       	movw	r26, r28
 6c6:	d1 96       	adiw	r26, 0x31	; 49
 6c8:	01 90       	ld	r0, Z+
 6ca:	0d 92       	st	X+, r0
 6cc:	8a 95       	dec	r24
 6ce:	e1 f7       	brne	.-8      	; 0x6c8 <main+0x44>
	};
	
	uint8_t roundkeys[AES_ROUND_KEY_SIZE];

	// key schedule
	aes_key_schedule_128(key, roundkeys);
 6d0:	be 01       	movw	r22, r28
 6d2:	6f 5b       	subi	r22, 0xBF	; 191
 6d4:	7f 4f       	sbci	r23, 0xFF	; 255
 6d6:	ce 01       	movw	r24, r28
 6d8:	01 96       	adiw	r24, 0x01	; 1
 6da:	0e 94 a7 02 	call	0x54e	; 0x54e <aes_key_schedule_128>

	// encryption
	aes_encrypt_128(roundkeys, plaintext, ciphertext);
 6de:	ae 01       	movw	r20, r28
 6e0:	4f 5d       	subi	r20, 0xDF	; 223
 6e2:	5f 4f       	sbci	r21, 0xFF	; 255
 6e4:	be 01       	movw	r22, r28
 6e6:	6f 5e       	subi	r22, 0xEF	; 239
 6e8:	7f 4f       	sbci	r23, 0xFF	; 255
 6ea:	ce 01       	movw	r24, r28
 6ec:	8f 5b       	subi	r24, 0xBF	; 191
 6ee:	9f 4f       	sbci	r25, 0xFF	; 255
 6f0:	0e 94 9f 01 	call	0x33e	; 0x33e <aes_encrypt_128>

	for (i = 0; i < AES_BLOCK_SIZE; i++) {
		if ( ciphertext[i] != const_cipher[i] ) { break; }
 6f4:	99 a1       	ldd	r25, Y+33	; 0x21
 6f6:	89 a9       	ldd	r24, Y+49	; 0x31
 6f8:	98 13       	cpse	r25, r24
 6fa:	0e c0       	rjmp	.+28     	; 0x718 <main+0x94>
 6fc:	fe 01       	movw	r30, r28
 6fe:	b2 96       	adiw	r30, 0x22	; 34
 700:	de 01       	movw	r26, r28
 702:	d2 96       	adiw	r26, 0x32	; 50
 704:	9e 01       	movw	r18, r28
 706:	2f 5c       	subi	r18, 0xCF	; 207
 708:	3f 4f       	sbci	r19, 0xFF	; 255
 70a:	91 91       	ld	r25, Z+
 70c:	8d 91       	ld	r24, X+
 70e:	98 13       	cpse	r25, r24
 710:	03 c0       	rjmp	.+6      	; 0x718 <main+0x94>
	aes_key_schedule_128(key, roundkeys);

	// encryption
	aes_encrypt_128(roundkeys, plaintext, ciphertext);

	for (i = 0; i < AES_BLOCK_SIZE; i++) {
 712:	e2 17       	cp	r30, r18
 714:	f3 07       	cpc	r31, r19
 716:	c9 f7       	brne	.-14     	; 0x70a <main+0x86>
		if ( ciphertext[i] != const_cipher[i] ) { break; }
	}


	// decryption
	aes_decrypt_128(roundkeys, ciphertext, plaintext);
 718:	ae 01       	movw	r20, r28
 71a:	4f 5e       	subi	r20, 0xEF	; 239
 71c:	5f 4f       	sbci	r21, 0xFF	; 255
 71e:	be 01       	movw	r22, r28
 720:	6f 5d       	subi	r22, 0xDF	; 223
 722:	7f 4f       	sbci	r23, 0xFF	; 255
 724:	ce 01       	movw	r24, r28
 726:	8f 5b       	subi	r24, 0xBF	; 191
 728:	9f 4f       	sbci	r25, 0xFF	; 255
 72a:	0e 94 4b 00 	call	0x96	; 0x96 <aes_decrypt_128>
	for (i = 0; i < AES_BLOCK_SIZE; i++) {
		if ( ciphertext[i] != plaintext[i] ) { break; }
 72e:	99 a1       	ldd	r25, Y+33	; 0x21
 730:	89 89       	ldd	r24, Y+17	; 0x11
 732:	98 13       	cpse	r25, r24
 734:	0e c0       	rjmp	.+28     	; 0x752 <main+0xce>
 736:	fe 01       	movw	r30, r28
 738:	b2 96       	adiw	r30, 0x22	; 34
 73a:	de 01       	movw	r26, r28
 73c:	52 96       	adiw	r26, 0x12	; 18
 73e:	9e 01       	movw	r18, r28
 740:	2f 5c       	subi	r18, 0xCF	; 207
 742:	3f 4f       	sbci	r19, 0xFF	; 255
 744:	91 91       	ld	r25, Z+
 746:	8d 91       	ld	r24, X+
 748:	98 13       	cpse	r25, r24
 74a:	03 c0       	rjmp	.+6      	; 0x752 <main+0xce>
	}


	// decryption
	aes_decrypt_128(roundkeys, ciphertext, plaintext);
	for (i = 0; i < AES_BLOCK_SIZE; i++) {
 74c:	e2 17       	cp	r30, r18
 74e:	f3 07       	cpc	r31, r19
 750:	c9 f7       	brne	.-14     	; 0x744 <main+0xc0>
		if ( ciphertext[i] != plaintext[i] ) { break; }
	}

	return 0;
}
 752:	80 e0       	ldi	r24, 0x00	; 0
 754:	90 e0       	ldi	r25, 0x00	; 0
 756:	c0 51       	subi	r28, 0x10	; 16
 758:	df 4f       	sbci	r29, 0xFF	; 255
 75a:	0f b6       	in	r0, 0x3f	; 63
 75c:	f8 94       	cli
 75e:	de bf       	out	0x3e, r29	; 62
 760:	0f be       	out	0x3f, r0	; 63
 762:	cd bf       	out	0x3d, r28	; 61
 764:	df 91       	pop	r29
 766:	cf 91       	pop	r28
 768:	08 95       	ret

0000076a <_exit>:
 76a:	f8 94       	cli

0000076c <__stop_program>:
 76c:	ff cf       	rjmp	.-2      	; 0x76c <__stop_program>
